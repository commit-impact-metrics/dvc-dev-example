{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import tempfile\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dvc_diff(old_commit, new_commit=None):\n",
    "    \"\"\"\n",
    "    Получение изменений DVC между двумя коммитами.\n",
    "\n",
    "    :param old_commit: Старый Git-коммит (a_rev).\n",
    "    :param new_commit: Новый Git-коммит (b_rev). Если None, сравнивается с текущим workspace.\n",
    "    :return: Словарь с изменениями.\n",
    "    \"\"\"\n",
    "    # Формируем базовую команду\n",
    "    cmd = [\"dvc\", \"diff\", \"--json\"]\n",
    "\n",
    "    # Добавляем старый и новый коммиты, если они указаны\n",
    "    if old_commit:\n",
    "        cmd.append(old_commit)\n",
    "    if new_commit:\n",
    "        cmd.append(new_commit)\n",
    "\n",
    "    # Выполняем команду\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    # Проверяем наличие ошибок\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"Error running 'dvc diff': {result.stderr.strip()}\")\n",
    "\n",
    "    # Возвращаем результат в виде словаря\n",
    "    return json.loads(result.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_code_changes(old_commit, new_commit):\n",
    "    \"\"\"\n",
    "    Подсчёт изменений в строках кода (.py файлы) между двумя коммитами.\n",
    "\n",
    "    :param old_commit: Старый Git-коммит.\n",
    "    :param new_commit: Новый Git-коммит.\n",
    "    :return: Словарь с количеством добавленных и удалённых строк.\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"diff\", \"--numstat\", f\"{old_commit}..{new_commit}\", \"--\", \"*.py\"]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"Error running 'git diff': {result.stderr.strip()}\")\n",
    "\n",
    "    added_lines = 0\n",
    "    deleted_lines = 0\n",
    "\n",
    "    # Разбираем строки вывода\n",
    "    for line in result.stdout.strip().split(\"\\n\"):\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        parts = line.split(\"\\t\")\n",
    "        added_lines += int(parts[0]) if parts[0].isdigit() else 0\n",
    "        deleted_lines += int(parts[1]) if parts[1].isdigit() else 0\n",
    "\n",
    "    return {\"added\": added_lines, \"deleted\": deleted_lines}\n",
    "\n",
    "\n",
    "def calculate_data_changes(dvc_diff):\n",
    "    \"\"\"\n",
    "    Подсчёт изменений в данных на основе DVC diff.\n",
    "\n",
    "    :param dvc_diff: Результат функции get_dvc_diff.\n",
    "    :return: Словарь с добавленными, удалёнными и модифицированными данными.\n",
    "    \"\"\"\n",
    "    changes = {\"added\": 0, \"deleted\": 0, \"modified\": 0}\n",
    "\n",
    "    # Обрабатываем добавленные файлы\n",
    "    for item in dvc_diff.get(\"added\", []):\n",
    "        path = item[\"path\"]\n",
    "        if os.path.isfile(path):\n",
    "            changes[\"added\"] += os.path.getsize(path)\n",
    "\n",
    "    # Обрабатываем удалённые файлы\n",
    "    for item in dvc_diff.get(\"deleted\", []):\n",
    "        # Пример: вместо размера, можно учитывать другое свойство\n",
    "        changes[\"deleted\"] += 1\n",
    "\n",
    "    # Обрабатываем модифицированные файлы\n",
    "    for item in dvc_diff.get(\"modified\", []):\n",
    "        old_hash = item.get(\"hash\", {}).get(\"old\")\n",
    "        new_hash = item.get(\"hash\", {}).get(\"new\")\n",
    "        if old_hash and new_hash:\n",
    "            # Здесь можно добавить более сложный анализ\n",
    "            changes[\"modified\"] += 1\n",
    "\n",
    "    return changes\n",
    "\n",
    "\n",
    "def analyze_changes(old_commit, new_commit):\n",
    "    \"\"\"\n",
    "    Анализ изменений в коде и данных между двумя коммитами.\n",
    "\n",
    "    :param old_commit: Старый Git-коммит.\n",
    "    :param new_commit: Новый Git-коммит.\n",
    "    :return: Сводная информация об изменениях.\n",
    "    \"\"\"\n",
    "    # Получаем изменения кода\n",
    "    code_changes = calculate_code_changes(old_commit, new_commit)\n",
    "\n",
    "    # Получаем изменения данных\n",
    "    dvc_diff = get_dvc_diff(old_commit, new_commit)\n",
    "    data_changes = calculate_data_changes(dvc_diff)\n",
    "\n",
    "    # Объединяем результаты\n",
    "    return {\"code_changes\": code_changes, \"data_changes\": data_changes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_metrics_to_file(commit, metrics, output_dir):\n",
    "    \"\"\"\n",
    "    Сохраняет метрики для заданного коммита в JSON файл.\n",
    "\n",
    "    :param commit: Хэш коммита.\n",
    "    :param metrics: Метрики (словарь).\n",
    "    :param output_dir: Папка для сохранения.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, f\"{commit}.json\")\n",
    "    with open(output_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=4)\n",
    "\n",
    "\n",
    "def get_git_commits(repo_path, n):\n",
    "    \"\"\"\n",
    "    Получает последние n коммитов в репозитории.\n",
    "\n",
    "    :param repo_path: Путь к репозиторию.\n",
    "    :param n: Количество последних коммитов.\n",
    "    :return: Список хэшей коммитов (от старых к новым).\n",
    "    \"\"\"\n",
    "    cmd = [\"git\", \"log\", \"--format=%H\", f\"-n{n}\"]\n",
    "    result = subprocess.run(cmd, cwd=repo_path, capture_output=True, text=True)\n",
    "\n",
    "    if result.returncode != 0:\n",
    "        raise RuntimeError(f\"Error running 'git log': {result.stderr.strip()}\")\n",
    "\n",
    "    return result.stdout.strip().split(\"\\n\")\n",
    "\n",
    "\n",
    "def count_lines_in_file(file_path):\n",
    "    \"\"\"\n",
    "    Подсчитывает количество строк в файле.\n",
    "\n",
    "    :param file_path: Путь к файлу.\n",
    "    :return: Количество строк.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as f:\n",
    "            return sum(1 for _ in f)\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file {file_path}: {e}\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def analyze_changes(repo_path, old_commit, new_commit):\n",
    "    \"\"\"\n",
    "    Анализирует изменения между двумя коммитами.\n",
    "\n",
    "    :param repo_path: Путь к репозиторию.\n",
    "    :param old_commit: Старый коммит.\n",
    "    :param new_commit: Новый коммит.\n",
    "    :return: Метрики изменений.\n",
    "    \"\"\"\n",
    "    # Переключаемся на старый коммит\n",
    "    subprocess.run([\"git\", \"checkout\", old_commit], cwd=repo_path, check=True)\n",
    "    subprocess.run([\"dvc\", \"checkout\"], cwd=repo_path, check=True)\n",
    "\n",
    "    # Сохраняем состояние файлов в старом коммите\n",
    "    old_state = {}\n",
    "    for root, _, files in os.walk(os.path.join(repo_path, \"data\")):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            old_state[file_path] = count_lines_in_file(file_path)\n",
    "\n",
    "    # Переключаемся на новый коммит\n",
    "    subprocess.run([\"git\", \"checkout\", new_commit], cwd=repo_path, check=True)\n",
    "    subprocess.run([\"dvc\", \"checkout\"], cwd=repo_path, check=True)\n",
    "\n",
    "    # Сохраняем состояние файлов в новом коммите\n",
    "    new_state = {}\n",
    "    for root, _, files in os.walk(os.path.join(repo_path, \"data\")):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            new_state[file_path] = count_lines_in_file(file_path)\n",
    "\n",
    "    # Анализируем изменения\n",
    "    added = 0\n",
    "    deleted = 0\n",
    "    modified = 0\n",
    "\n",
    "    all_files = set(old_state.keys()).union(set(new_state.keys()))\n",
    "    for file_path in all_files:\n",
    "        old_lines = old_state.get(file_path, 0)\n",
    "        new_lines = new_state.get(file_path, 0)\n",
    "\n",
    "        if old_lines == 0 and new_lines > 0:\n",
    "            added += new_lines\n",
    "        elif old_lines > 0 and new_lines == 0:\n",
    "            deleted += old_lines\n",
    "        elif old_lines != new_lines:\n",
    "            modified += abs(new_lines - old_lines)\n",
    "\n",
    "    return {\n",
    "        \"added_lines\": added,\n",
    "        \"deleted_lines\": deleted,\n",
    "        \"modified_lines\": modified,\n",
    "    }\n",
    "\n",
    "\n",
    "def analyze_commit_series(n, output_dir):\n",
    "    \"\"\"\n",
    "    Анализирует последние n коммитов и записывает результаты в папку output_dir.\n",
    "\n",
    "    :param n: Количество последних коммитов.\n",
    "    :param output_dir: Папка для сохранения результатов.\n",
    "    \"\"\"\n",
    "    commits = get_git_commits(n)\n",
    "\n",
    "    with tempfile.TemporaryDirectory() as temp_repo:\n",
    "        # Клонируем текущий репозиторий во временную директорию\n",
    "        subprocess.run([\"git\", \"clone\", \".\", temp_repo], check=True)\n",
    "\n",
    "        for i in range(len(commits) - 1):\n",
    "            old_commit = commits[i]\n",
    "            new_commit = commits[i + 1]\n",
    "\n",
    "            print(f\"Analyzing commit: {new_commit} (compare with {old_commit})\")\n",
    "\n",
    "            try:\n",
    "                # Анализируем изменения между коммитами\n",
    "                metrics = analyze_changes(temp_repo, old_commit, new_commit)\n",
    "\n",
    "                # Сохраняем результаты в файл\n",
    "                save_metrics_to_file(new_commit, metrics, output_dir)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing commit {new_commit}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Клонирование в «/var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmpdmc88t5r»...\n",
      "готово.\n",
      "Примечание: переключение на «a3118823752fd0d2a35586635c2a07ba3d90e624».\n",
      "\n",
      "Вы сейчас в состоянии «отсоединённого указателя HEAD». Можете осмотреться,\n",
      "внести экспериментальные изменения и зафиксировать их, также можете\n",
      "отменить любые коммиты, созданные в этом состоянии, не затрагивая другие\n",
      "ветки, переключившись обратно на любую ветку.\n",
      "\n",
      "Если хотите создать новую ветку для сохранения созданных коммитов, можете\n",
      "сделать это (сейчас или позже), используя команду switch с параметром -c.\n",
      "Например:\n",
      "\n",
      "  git switch -c <новая-ветка>\n",
      "\n",
      "Или отмените эту операцию с помощью:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Отключите этот совет, установив переменную конфигурации\n",
      "advice.detachedHead в значение false\n",
      "\n",
      "HEAD сейчас на a311882 notebook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing commit: 948967da5382375bb6e4073690e33fb83a7390ed (compare with a3118823752fd0d2a35586635c2a07ba3d90e624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Checkout failed for following targets:\n",
      "data/prepared\n",
      "data/features\n",
      "eval\n",
      "model.pkl\n",
      "data/data.xml\n",
      "Is your cache up to date?\n",
      "<https://error.dvc.org/missing-files>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error analyzing commit 948967da5382375bb6e4073690e33fb83a7390ed: Command '['dvc', 'checkout']' returned non-zero exit status 255.\n"
     ]
    }
   ],
   "source": [
    "analyze_commit_series(2, \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_file_states(repo_path):\n",
    "    \"\"\"\n",
    "    Собирает состояние файлов в репозитории.\n",
    "\n",
    "    :param repo_path: Путь к репозиторию.\n",
    "    :return: Словарь с состоянием файлов.\n",
    "    \"\"\"\n",
    "    file_states = {}\n",
    "    for root, _, files in os.walk(os.path.join(repo_path, \"data\")):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            file_states[file_path] = count_lines_in_file(file_path)\n",
    "    return file_states\n",
    "\n",
    "\n",
    "def analyze_changes_between_states(old_state, new_state):\n",
    "    \"\"\"\n",
    "    Анализирует изменения между двумя состояниями файлов.\n",
    "\n",
    "    :param old_state: Состояние файлов в старом коммите.\n",
    "    :param new_state: Состояние файлов в новом коммите.\n",
    "    :return: Метрики изменений.\n",
    "    \"\"\"\n",
    "    added = 0\n",
    "    deleted = 0\n",
    "    modified = 0\n",
    "\n",
    "    all_files = set(old_state.keys()).union(set(new_state.keys()))\n",
    "    for file_path in all_files:\n",
    "        old_lines = old_state.get(file_path, 0)\n",
    "        new_lines = new_state.get(file_path, 0)\n",
    "\n",
    "        if old_lines == 0 and new_lines > 0:\n",
    "            added += new_lines\n",
    "        elif old_lines > 0 and new_lines == 0:\n",
    "            deleted += old_lines\n",
    "        elif old_lines != new_lines:\n",
    "            modified += abs(new_lines - old_lines)\n",
    "\n",
    "    return {\n",
    "        \"added_lines\": added,\n",
    "        \"deleted_lines\": deleted,\n",
    "        \"modified_lines\": modified,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import shutil\n",
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "\n",
    "\n",
    "def clone_and_prepare_repo(repo_path, branch=None):\n",
    "    \"\"\"Клонирует репозиторий в временную папку.\"\"\"\n",
    "    temp_dir = tempfile.mkdtemp()\n",
    "    subprocess.run([\"git\", \"clone\", repo_path, temp_dir], check=True)\n",
    "    if branch:\n",
    "        subprocess.run([\"git\", \"checkout\", branch], cwd=temp_dir, check=True)\n",
    "    return temp_dir\n",
    "\n",
    "\n",
    "def pull_dvc_cache(repo_dir):\n",
    "    \"\"\"Пытается загрузить кэш DVC, если возможно.\"\"\"\n",
    "    try:\n",
    "        subprocess.run([\"dvc\", \"pull\"], cwd=repo_dir, check=True)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Warning: Could not pull DVC cache. Error: {e}\")\n",
    "\n",
    "\n",
    "def analyze_commit_series_with_cache(repo_path, n, output_dir):\n",
    "    \"\"\"\n",
    "    Анализирует последние n коммитов и записывает результаты в output_dir.\n",
    "    Работает с временным клоном репозитория.\n",
    "    \"\"\"\n",
    "    temp_repo = clone_and_prepare_repo(repo_path)\n",
    "    try:\n",
    "        commits = get_git_commits(temp_repo, n)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        for i in range(len(commits) - 1):\n",
    "            old_commit = commits[i]\n",
    "            new_commit = commits[i + 1]\n",
    "            print(f\"Analyzing commit: {new_commit} (compare with {old_commit})\")\n",
    "\n",
    "            try:\n",
    "                subprocess.run(\n",
    "                    [\"git\", \"checkout\", old_commit], cwd=temp_repo, check=True\n",
    "                )\n",
    "                pull_dvc_cache(temp_repo)  # Попытка загрузить кэш для старого коммита\n",
    "                old_state = collect_file_states(temp_repo)\n",
    "\n",
    "                subprocess.run(\n",
    "                    [\"git\", \"checkout\", new_commit], cwd=temp_repo, check=True\n",
    "                )\n",
    "                pull_dvc_cache(temp_repo)  # Попытка загрузить кэш для нового коммита\n",
    "                new_state = collect_file_states(temp_repo)\n",
    "\n",
    "                metrics = analyze_changes_between_states(old_state, new_state)\n",
    "                save_metrics_to_file(new_commit, metrics, output_dir)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error analyzing commit {new_commit}: {e}\")\n",
    "\n",
    "    finally:\n",
    "        shutil.rmtree(temp_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_two_commits_with_cache(repo_path, old_commit, new_commit, output_dir):\n",
    "    \"\"\"\n",
    "    Анализирует изменения между двумя коммитами и записывает результаты в output_dir.\n",
    "    Работает с временным клоном репозитория.\n",
    "    \"\"\"\n",
    "    temp_repo = clone_and_prepare_repo(repo_path)\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        print(f\"Analyzing commit: {new_commit} (compare with {old_commit})\")\n",
    "\n",
    "        try:\n",
    "            subprocess.run([\"git\", \"checkout\", old_commit], cwd=temp_repo, check=True)\n",
    "            pull_dvc_cache(temp_repo)  # Попытка загрузить кэш для старого коммита\n",
    "            old_state = collect_file_states(temp_repo)\n",
    "\n",
    "            subprocess.run([\"git\", \"checkout\", new_commit], cwd=temp_repo, check=True)\n",
    "            pull_dvc_cache(temp_repo)  # Попытка загрузить кэш для нового коммита\n",
    "            new_state = collect_file_states(temp_repo)\n",
    "\n",
    "            metrics = analyze_changes_between_states(old_state, new_state)\n",
    "            save_metrics_to_file(new_commit, metrics, output_dir)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing commit {new_commit}: {e}\")\n",
    "\n",
    "    finally:\n",
    "        shutil.rmtree(temp_repo)\n",
    "\n",
    "\n",
    "def compare_branches(repo_path, branch1, branch2, output_dir):\n",
    "    \"\"\"\n",
    "    Сравнивает HEAD коммиты двух веток и записывает результаты в output_dir.\n",
    "\n",
    "    :param repo_path: Путь к репозиторию.\n",
    "    :param branch1: Первая ветка.\n",
    "    :param branch2: Вторая ветка.\n",
    "    :param output_dir: Папка для сохранения результатов.\n",
    "    \"\"\"\n",
    "    temp_repo = clone_and_prepare_repo(repo_path)\n",
    "    try:\n",
    "        # Получаем последний коммит для каждой ветки\n",
    "        subprocess.run([\"git\", \"checkout\", branch1], cwd=temp_repo, check=True)\n",
    "        head_commit_branch1 = subprocess.run(\n",
    "            [\"git\", \"rev-parse\", \"HEAD\"], cwd=temp_repo, capture_output=True, text=True\n",
    "        ).stdout.strip()\n",
    "\n",
    "        subprocess.run([\"git\", \"checkout\", branch2], cwd=temp_repo, check=True)\n",
    "        head_commit_branch2 = subprocess.run(\n",
    "            [\"git\", \"rev-parse\", \"HEAD\"], cwd=temp_repo, capture_output=True, text=True\n",
    "        ).stdout.strip()\n",
    "\n",
    "        # Анализируем изменения между коммитами\n",
    "        analyze_two_commits_with_cache(\n",
    "            repo_path, head_commit_branch1, head_commit_branch2, output_dir\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error comparing branches {branch1} and {branch2}: {e}\")\n",
    "\n",
    "    finally:\n",
    "        shutil.rmtree(temp_repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Клонирование в «/var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9»...\n",
      "готово.\n",
      "Примечание: переключение на «a3118823752fd0d2a35586635c2a07ba3d90e624».\n",
      "\n",
      "Вы сейчас в состоянии «отсоединённого указателя HEAD». Можете осмотреться,\n",
      "внести экспериментальные изменения и зафиксировать их, также можете\n",
      "отменить любые коммиты, созданные в этом состоянии, не затрагивая другие\n",
      "ветки, переключившись обратно на любую ветку.\n",
      "\n",
      "Если хотите создать новую ветку для сохранения созданных коммитов, можете\n",
      "сделать это (сейчас или позже), используя команду switch с параметром -c.\n",
      "Например:\n",
      "\n",
      "  git switch -c <новая-ветка>\n",
      "\n",
      "Или отмените эту операцию с помощью:\n",
      "\n",
      "  git switch -\n",
      "\n",
      "Отключите этот совет, установив переменную конфигурации\n",
      "advice.detachedHead в значение false\n",
      "\n",
      "HEAD сейчас на a311882 notebook\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing commit: 948967da5382375bb6e4073690e33fb83a7390ed (compare with a3118823752fd0d2a35586635c2a07ba3d90e624)\n",
      "A       model.pkl\n",
      "A       eval/\n",
      "A       data/data.xml\n",
      "A       data/features/\n",
      "A       data/prepared/\n",
      "5 files added and 17 files fetched\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предыдущая позиция HEAD была a311882 notebook\n",
      "HEAD сейчас на 948967d upd: add local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Analyzing commit: 06ea48980a34ef57041c9b905cafcb40d9c3ddbc (compare with 948967da5382375bb6e4073690e33fb83a7390ed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD сейчас на 948967d upd: add local storage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предыдущая позиция HEAD была 948967d upd: add local storage\n",
      "HEAD сейчас на 06ea489 Evaluate bigrams model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Analyzing commit: e4bc9b0445bce5d075d1a4b8a7bd758e1d4eb1cb (compare with 06ea48980a34ef57041c9b905cafcb40d9c3ddbc)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD сейчас на 06ea489 Evaluate bigrams model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предыдущая позиция HEAD была 06ea489 Evaluate bigrams model\n",
      "HEAD сейчас на e4bc9b0 Reproduce model using bigrams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       eval/\n",
      "1 file modified and 9 files fetched\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Analyzing commit: 0d46eb42e874eb1f681adda2aa772b6d1ea2bb97 (compare with e4bc9b0445bce5d075d1a4b8a7bd758e1d4eb1cb)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD сейчас на e4bc9b0 Reproduce model using bigrams\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предыдущая позиция HEAD была e4bc9b0 Reproduce model using bigrams\n",
      "HEAD сейчас на 0d46eb4 Create evaluation stage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M       model.pkl\n",
      "M       data/features/\n",
      "2 files modified and 4 files fetched\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Analyzing commit: 5d3ccf58b626f3144901e273cced02a8768bf2a0 (compare with 0d46eb42e874eb1f681adda2aa772b6d1ea2bb97)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD сейчас на 0d46eb4 Create evaluation stage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предыдущая позиция HEAD была 0d46eb4 Create evaluation stage\n",
      "HEAD сейчас на 5d3ccf5 Create ML pipeline stages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D       eval/\n",
      "1 file deleted\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Analyzing commit: 6c5ba05dcb60edd3911fc2e78433f8ec71425ef1 (compare with 5d3ccf58b626f3144901e273cced02a8768bf2a0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD сейчас на 5d3ccf5 Create ML pipeline stages\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/train.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n",
      "Error reading file /var/folders/72/p2x4tpws2gl6wkm3bp268fr00000gn/T/tmprm64ghx9/data/features/test.pkl: 'utf-8' codec can't decode byte 0x80 in position 0: invalid start byte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предыдущая позиция HEAD была 5d3ccf5 Create ML pipeline stages\n",
      "HEAD сейчас на 6c5ba05 Create data preparation stage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D       model.pkl\n",
      "D       data/features/\n",
      "2 files deleted\n",
      "Analyzing commit: 43706283de3c2b51a390d37d58ce74008514609e (compare with 6c5ba05dcb60edd3911fc2e78433f8ec71425ef1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD сейчас на 6c5ba05 Create data preparation stage\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предыдущая позиция HEAD была 6c5ba05 Create data preparation stage\n",
      "HEAD сейчас на 4370628 Add source code files to repo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D       data/prepared/\n",
      "1 file deleted\n",
      "Analyzing commit: 64764c6f48a602cd2885d03cc98dcbc5f0429604 (compare with 43706283de3c2b51a390d37d58ce74008514609e)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD сейчас на 4370628 Add source code files to repo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предыдущая позиция HEAD была 4370628 Add source code files to repo\n",
      "HEAD сейчас на 64764c6 Import raw data (overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n",
      "Analyzing commit: d82611b3d0ef19a0636784e5c880cd2ce7c3c9c3 (compare with 64764c6f48a602cd2885d03cc98dcbc5f0429604)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HEAD сейчас на 64764c6 Import raw data (overwrite)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Предыдущая позиция HEAD была 64764c6 Import raw data (overwrite)\n",
      "HEAD сейчас на d82611b Configure default remote\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything is up to date.\n"
     ]
    }
   ],
   "source": [
    "analyze_commit_series_with_cache(repo_path=\".\", n=10, output_dir=\"commit_metrics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
